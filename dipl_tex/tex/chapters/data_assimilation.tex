\chapter{Datenassimilation}
\section{Problemstellung}
Die 4-D Variations-Datenassimilation ist eine Methode, welche versucht, die Theorie der optimalen Steuerung auf die Datemassimilation, also das Annähern eines Modells an observierte Parameter durch Steuerungsparameter, zu übertragen.
Eingeführt von Talagrand und Le Dimet in \cite{dimet1986variational} findet diese Methode immer mehr Verwendung für reale Beispiele (z.B. \cite{korotaev2008retrieving,elbern20004d,broquet2009application}). Benutzt wird sie meist in atmosphärischen Modellen, um optimale Parameter zur numerischen Wettervorhersage zu finden. Auch in ozeanographischen Modellen findet diese Methode Anwendung.

Ziel der 4-D Datenassimilation ist es durch Steuerungsparameter, wie etwa Anfangswerte zum Zeitpunkt $t_0$, den Abstand eines Modells gegenüber den in der Zeit gemessenen Observierungsparametern minimal werden zu lassen. 

Um diese Methode herzuleiten folgen wir der Herangehensweise von Talagrand in \cite{talagrand1987variational} und nehmen zuerst die Evolutionsgleichung
\begin{equation}
\label{eq:odemodel}
 \frac{dx}{dt} = F(x)\quad \text{mit} \quad x(0) = x_0 \quad \text{und}\quad F:\R^n\to \R^n
\end{equation}
  
welche eine Gewöhnliche Differentialgleichung beschreibt. Dabei ist $x$ die zeitabhängige Zustandsvariable aus dem Hilbertraum $\R^n$, welche die Entwicklung des Systems zu einem Zeitpunkt $t\in \R$ beschreibt. 
Der Anfangswert sei dabei $x_0 \in \R^n$, welcher gleichzeitig der Steuerungsparameter ist.
Die Observierungsparameter $\xobs$ sind diskrete Werte oder Funktionen, welche orts - und zeitabhängig und über ein Intervall $[0,T]$ verteilt sind. Da $\xobs$  nicht zwangsweise im Zustandsraum $\Xstate$ lebt, wird eine Projektion $C:\Xstate\to \Xobs$ benötigt, welche $x$ aus $\Xstate$ in den Observierungsraum $\Xobs$ abbildet. Üblicherweise ist diese Funktion eine Auswertungsfunktion von $x$ an den Stellen $\tobs$.

Als Kostenfunktional dient die $L^2$ - Norm der Differenz der Lösung $x$ von \eqref{eq:odemodel} zu $\xobs$ über ein gegebenes Zeitintervall $[0,T]$
\begin{equation}
\label{eq:costfunctional}
 J(x_0) = \frac{1}{2}\int_0^T H(x(t),t)dt= \frac{1}{2}\int_0^T \|C\cdot x(V)-\xobs\|^2dt
\end{equation}
Die skalarwertige Funktion $J$ ist damit jene Funktion, die das Maß zwischen der Lösung $x$ und den Observierungsparametern $\xobs$ darstellt.
Man beachte, dass das Zielfunktional nur abhängig vom Anfangswert $x_0$ ist. Das Ziel besteht darin, $x_0 = x_0^*$ zu finden, sodass das unrestringierte Optimierungsproblem
\begin{equation}
\label{eq:bolzaProblem}
\begin{aligned}
 J(x_0^*) =& \min_{x_0} J(x_0) \\
 &\text{s.d. } \dot x = F(x(t)) \text{ und } x(0) = x_0
\end{aligned}
\end{equation}

gelöst wird. 
In der Literatur ist dieses Problem auch als \textit{Bolza Problem} bekannt. Clarke gibt in seinem Buch \cite[S. 165 ff]{clarke1990optimization} eine Einführung in ein verallgemeinertes Problem, in dieser Arbeit werden wir uns auf das oben Diskutierte beschränken.

Die Grundlage zur Minimierung des Kostenfunktionals stellt zunächst die Lösungstheorie zu gewöhnlichen Differentialgleichungen dar.

\section{Gewöhnliche Differentialgleichungen}
Eine Gleichung der Form \eqref{eq:odemodel} wird eine \textit{gewöhnliche Differentialgleichung erster Ordnung} genannt. 
In der nachfolgend betrachteten Theorie sowie in der Implementation der Verfahren in dieser Arbeit werden ausschließlich autonome Gewöhnliche Differentialgleichungen erster Ordnung betrachtet, da sich sämtliche Gewöhnliche Differentialgleichungen in diese Form überführen lassen.
Falls eine Differentialgleichung n-ter Ordnung der Form 
\[
 \frac{d^n x}{dt^n}= F\left(t;x,\frac{dx}{dt},\ldots,\frac{d^{n-1} x}{dt^{n-1}}\right)
\]
mit $F$ differenzierbar, gegeben ist, ist wohlbekannt, dass sie sich durch Hinzufügen zusätzlicher Variablen in ein Differentialgleichungssystem erster Ordnung mittels
\[
 \dot x_0=t\quad \dot x_1 = x_2 \quad ,\ldots,\quad \dot x_{n-1} = x_n, \quad  \dot x_n = F(x_0;x_1,\ldots,x_{n-1})
\]
überführen lassen (\cite[S. 105]{arnold2001grundbegriffe}).
Durch die Einführung einer weiteren Variablen $x_0 = t$ und Gleichung $\dot x_0=1$ lässt sich die gegebene ODE autonom, also die rechte Seite $F$ unabhängig von der Zeit $t$, schreiben.
\subsection{Grundlagen}
Die Existenz und Eindeutigkeit von Lösungen wird durch den Satz von Picard-Lindelöf (z.B.\cite{teschl2012ordinary}) beschrieben, der die Grundlage zur Lösungstheorie Gewöhnlicher Differentialgleichungen bildet.
\begin{theorem}[Picard-Lindelöf]
\label{thm:picard-lindeloeff}
 Sei $F\in C(U,\R^n)$, wobei $U$ eine offene Teilmenge von $\R^{n+1}$ und $(t_0,x_0)\in U$ ist. Falls $F$ im zweiten Argument lokal lipschitzstetig und gleichmäßig stetig im ersten Argument ist, dann existiert eine eindeutige lokale Lösung $\bar x(t)\in C^1(I)$ des Anfangswertproblems \eqref{eq:odemodel}, wobei $I$ ein Intervall um $t_0$ ist.
\end{theorem}
% 
% Ein Spezialfall des Modells \eqref{eq:odemodel}, welche wir im Folgenden benötigen werden, sind die Matrix Differentialgleichungen, welche die Form
% \[
%  \frac{d}{dt} X = A(t)X,\quad \frac{d}{dt}X(t) =[\frac{d}{dt}x_{ij}(t)] 
% \]
% besitzen, mit $A\in R^{n\times n}$


% \[
%  \dot x \in F(t,x)
% \]
Falls eine gewöhnliche Differentialgleichung keine stetige rechte Seite besitzt, kann trotzdem eine Aussage zur Existenz einer Lösung getroffen werden. Filippov beschreibt in \cite{filippov1971existence} die Existenz einer Lösung für Multifunktionen $F(x):\mathcal D \rightrightarrows R^n$ falls diese jedoch \textit{oberhalbstetig} sind. 
\begin{theorem}[Filippov]
 Sei U wie in \ref{thm:picard-lindeloeff} gegeben und $D\subset U$. Sei $F:D\rightrightarrows \R^n$ eine mengenwertige Abbildung. Für alle Punkte der Region $D$ sei $F(t,x)$ eine nichtleere beschränkte abgeschlossene Menge. Desweiteren sei $F(t,x)$ oberhalbstetig, also für alle $(t,x)\in D$ und alle $\varepsilon>0$ existiert ein $\delta = \delta(\varepsilon,t,x)>0$, sodass für alle Punkte $(t',x')$ der $\delta$- Umgebung von $(t,x)$ die Menge $F(t',x')$ in der $\varepsilon$-Umgebung der Menge $F(t,x)$ liegt.
 Wenn nun $F(t,x)$ überall konvex ist, dann besitzt die Differentialinklusion
 \[
  \dot x \in F(t,x)
 \]
 für alle Anfangswerte $x(t_0)=x_0$ mit $(t_0,x_0)\in D$ mindestens eine Lösung.
\end{theorem}


\subsection{Numerik gewöhnlicher Differentialgleichungen}
In vielen Fällen lässt sich die Lösung eines Anfangswertproblems nicht oder nur sehr schwierig analytisch berechnen. Es ist daher sinnvoll, die Lösung numerisch zu approximieren. Da sie nicht in geschlossener Form darstellbar ist, sondern man die Werte nur an vorgegebenen diskreten Stellen erhält wird das Zeitintervall $[0,T]$ in $N+1$ diskrete Punkte
\[
 0\equiv t_0<t_1<\ldots < t_N \equiv T
\]
zerlegt. Diese Zeitpunkte bilden ein Gitter $G_h \equiv \lbrace t_0,t_1,\ldots, t_N\rbrace $ auf dem die Schrittweiten $h_j= t_{j+1}-t_j$, $j=0,\ldots, N-1$ definiert sind. Im Rahmen dieser Arbeit werden nur äquidistante Gitter verwendet, d.h. es gilt 
\[
h_0=h_1 = \ldots = h_{N-1} 
\]
 
Um nun numerische Approximationen der Lösung des Anfangswertproblemes zu erhalten, geht man von dessen Integraldarstellung 

\[
 x(t_{i+1}) = x(t_{i-k+1}) + \int_{t_i-k+1}^{t_i+1} F(\tau,x(\tau))d\tau
\]
aus, um eine Quadraturformel durch Interpolation zu erhalten (\cite[(1.55)]{hermann2004numerik})
\[
 x_{i+1} = x_{i-k+1} + \sum_{j=0}^k w_{ij} f(t_{i-j+1},x_{i-j+1})
\]
wobei die Parameter $w_{ij}$ durch das Verfahren vorgegeben sind. Falls $w_{i0}\neq 0$ wird von einem $k$-schrittigen \textit{impliziten Verfahren}, für $w_{i0} = 0$ von einem $k$-schrittigen \textit{expliziten Verfahren} gesprochen.

Für $k=1$ ergibt sich das sogenannte \textit{implizite} Einschrittverfahren, welches die Form
\[
 x_{i+1} = x_i + h_i \Phi (t_i,x_i,x_{i+1};h_i), ~ i=0,\ldots, N-1
\]
besitzt.
Ein \textit{explizites} Verfahren liegt vor, falls $\Phi$ nicht von $x_{i+1}$ abhängt. $\Phi$ wird die \textit{Inkrementfunktion} eines Einschrittverfahren genannt.
Ein Einschrittverfahren der Gestalt 
\[
 x_{i+1}^h = x_i^h + h\sum_{j=1}^m \beta_j k_j \quad \text{ mit } \quad k_j  = f(t_i+ \rho_ih, x_i^h + \sum_{l=1}^m \gamma_{jl} k_l ), \quad j=1,\ldots,m
\]
wird \textit{m- stufiges Runge Kutta Verfahren} genannt, mit $m\in \N$. Die Koeffizienten $\beta_j,\gamma_{jl}$ und $\rho_i$ sind geeignet gewählte, reelle Zahlen, die durch das Verfahren eindeutig gegeben sind. Diese Koeffizienten lassen sich in \textit{Butcher Tableaus} angegeben, welche dann ein Verfahren eindeutig beschreiben, wie beispielsweise in Abbildung \ref{tab:rungekutta} ersichtlich.

\begin{figure}[htdp]
 \centering
 \begin{tabular}{c c c c c}
% \begin{tabular}{ c | ccc }
%   $\rho_1$ & $\gamma_{11}$ &$\dots$ & $\gamma_{1m}$\\
%   $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$\\
%   $\rho_m$ & $\gamma_{m1}$ & $\dots$& $\gamma_{mm}$ \\
%   \hline
%    &$\beta_1$& $\dots$ & $\beta_m$ \\
% \end{tabular}
% &
\begin{tabular}{ c|  c }
 \multicolumn{1}{c}{}\\
 \multicolumn{1}{c}{}\\
  $\rho$ & $\Gamma$\\
  \hline
   &$\beta$
\end{tabular}
&
\begin{tabular}{ c|  c }
 \multicolumn{1}{c}{}\\
 \multicolumn{1}{c}{}\\
  $0$ & $0$\\
  \hline
   &$1$
\end{tabular}
&
\begin{tabular}{ c|  c c }
 \multicolumn{1}{c}{}\\
0 & \\
 $\frac{1}{2}$& $\frac{1}{2}$ & $0$\\
  \hline
   &$0$&$1$
\end{tabular}
&
\begin{tabular}{ c|  c }
 \multicolumn{1}{c}{}\\
 \multicolumn{1}{c}{}\\
  $\frac{1}{2}$ & $\frac{1}{2}$\\
  \hline
   &$1$
\end{tabular}
&
\begin{tabular}{ c| c c }
 \multicolumn{1}{c}{}\\
 0&0&0\\
  1 & $\frac{1}{2}$ & $\frac{1}{2}$\\
  \hline
   & $\frac{1}{2}$ &  $\frac{1}{2}$
\end{tabular}
\\
 Allgemein & Expl. Euler & \specialcell{Expl.\\ Mittelpunkts-\\regel} & \specialcell{Impl.\\ Mittelpunkts-\\regel} & \specialcell{Trapez-\\regel}
\end{tabular}
\caption{Beispiele zu $m$-stufigen Runge Kutta Verfahren}
\label{tab:rungekutta}
\end{figure}
Bei der Lösung impliziter Verfahren müssen Gleichungssysteme gelöst werden, welche den Berechnungsaufwand pro Schritt erhöhen. Explizite Verfahren sind schneller zu berechnen, jedoch fehleranfälliger für steife Probleme und im allgemeinen nicht so genau wie implizite Methoden. Im folgenden werden wir für die Lösung von gewöhnlichen Differentialgleichungen die Implizite Mittelpunktsregel benutzen. 

Durch das Lösen unseres Modells \eqref{eq:odemodel} mit einer der vorgestellten Methode lässt sich nun das Kostenfunktional $J(x_0)$ \eqref{eq:costfunctional} an einer Stelle $x_0$ berechnen. Das Ziel besteht nun darin, diese Funktion $J$ zu minimieren.
Bei den Optimierungsmethoden, welche wir betrachten, benötigt man den Gradienten von $J$.

\section{Der Gradient des Zielfunktionals}
\subsection{Adjungierte Operatoren}
Für höhere Dimensionen ist die Bestimmung dieses Gradienten jedoch auf klassischem Weg numerisch sehr komplex. Dazu würde man jede Komponente unseres Systems \eqref{eq:odemodel} stören, das gestörte Modell in jeder Komponente integrieren und das Kostenfunktional dieser ausrechnen. Aus der Störung würde sich der Gradient $\partial J/\partial x_0$ ergeben. Dies ist sehr ineffizient. Als effiziente Alternative hat sich die Anwendung adjungierter Methoden erwiesen. Mit ihrer Hilfe kann die numerische Komplexität der Berechnung des Gradienten auf ein weniges Vielfaches des Integrierens der Evolutionsgleichung \eqref{eq:odemodel} vermindert werden.

Eine allgemeine Einführung zur Theorie von adjungierten Gleichungen wurde beispielsweise von Cacuci \cite{cacuci1981sensitivity} gegeben, während Talagrand in \cite{talagrand1987variational} adjungierte Operatoren auf Hilberträume einschränkt und mit Diesen die Datenassimilation einführt.
Für die folgenden Betrachtungen sind Hilberträume von besonderer Wichtigkeit. Sämtliche Lösungstheorie sowohl bei gewöhnlichen als auch bei partiellen Differentialgleichungen basieren auf den speziellen Eigenschaften dieser Räume.

Ein Hilbertraum ist ein reller oder komplexer Vektorraum mit einem Skalarprodukt, der bzgl. der vom Skalarprodukt induzierten Norm vollständig ist. Da $\R$ vollständig ist, ist jeder endlichdimensionale Vektorraum versehen mit einem Skalarprodukt vollständig. In der numerischen Praxis sind damit sämtliche folgenden Schritte valide. 
Ein Ableitungsbegriff auf Hilberträumen ist die sogenannte Gâteaux Ableitung (z.B.\cite[]{lindenstrauss2003frechet}).
\begin{definition}[Gâteaux Ableitung]
 Seien $X$ und $Y$ Banachräume, $U \subset X$ offen und $F:X\to Y$. Das Gâteaux Differential $\gatdiff F(u;\psi)$ von F an $u\in U$ in Richtung $\psi\in X$ ist definiert als
 \[
  \gatdiff F(u;\psi) = \lim_{\tau \to 0} \frac{F(x+\tau \psi) - F(x)}{\tau} = \frac{d}{d\tau} F(u+\tau\psi)\biggr\rvert_{\tau = 0}\quad \forall \psi \in X
 \]
 falls der Grenzwert existiert. Existiert der Grenzwert für alle $\psi\in X$, dann heißt $F$ Gâteaux-Differenzierbar in $u$.
 Falls $X$ und $Y$ endlichdimensional sind, entspricht das Konzept der Gâteaux Ableitung der Richtungsableitung.
\end{definition}
Die folgende Definition der adjungierten Operatoren und Proposition von Hilberträumen sind besonders nützlich für nachfolgende Betrachtungen.
\begin{definition}[Adjungierte Operatoren]
Sei $\Gil$ ein anderer Hilbertraum mit Innenprodukt $\langle \cdot,\cdot \rangle_\Gil$ und $L$ ein stetiger linearer Operator $L:\mathcal{G}\to \Hil$. Dann existiert ein eindeutiger stetiger linearer Operator $L^*:\Hil\to\Gil$, sodass für alle $u\in \Gil$ und $v\in \Hil$ gilt
\begin{equation}
\label{eq:adjointInnerProduct}
\langle v,Lu\rangle_\Hil =  \langle L^*v,u \rangle_\Gil
\end{equation}
$L^*$ heißt der \textit{adjungierte Operator} von $L$ (vgl. \cite[Definition V.5.1]{werner2007funktionalanalysis}). Im Falle, dass $\Hil$ und $\Gil$ endlichdimensional sind und durch orthonormale Koordinaten beschrieben werden können, ist bekannt, dass  $L^*$ gerade die transponierte Matrix von $L$ ist.
%  , da $\langle x,L^*y\rangle = \langle Lx,y\rangle =(Lx)^\tr y  = x^\tr L^\tr y= \langle x,L^\tr y\rangle  $
\end{definition}
Die Gâteaux Ableitung einer differenzierbaren Funktion ergibt sich als Richtungsableitung (vgl. \cite[Example 9.2.4]{debnath2005hilbert})
\begin{proposition}[Gâteaux Ableitung differenzierbarer Funktionen]
\label{prop:adjoints}
Sei $\Hil$ ein Hilbertraum mit Skalarprodukt $\langle \cdot,\cdot \rangle_\Hil$ und $v:\Hil \to \R,~ v\mapsto J(v)$ eine einmal stetig differenzierbare skalare Funktion definiert auf $\Hil$. Das Gâteaux Differential $\gatdiff J$ von $J$ kann an jedem Punkt von $\Hil$ über das Gâteaux Differential $\gatdiff v$ von $v$ ausgedrückt werden als
 \begin{equation}
 \label{eq:diffInnerProduct}
  \gatdiff J(v;\gatdiff v) = \langle \nabla_v J, \gatdiff v\rangle_\Hil
 \end{equation}
 $\nabla_v J$ ist hierbei der eindeutige Gradient von $J$ in Richtung $v$ an der Stelle $x$, welche zur Übersichtlichkeit weggelassen wurde. Wenn $\Hil$ endlichdimensional und durch orthonormale Koordinaten $v_i$ beschrieben ist, dann sind die Komponenten von $\nabla_v J$ gerade die Vektoren der partiellen Ableitung von $J$ nach $v_i$, also $\partial J/\partial v_i$.
\end{proposition}


Seien $\Hil,~\Gil$ und $J$ wie in Proposition \ref{prop:adjoints} eingeführt. Betrachtet man jetzt eine Funktion $u:\Gil \to \Hil, ~u\mapsto v = G(u)$, G differenzierbar, so folgt, dass sich $J(v) = J(G(u))$ zu einer zusammengesetzte Funktion von $u$ ergibt. Nun gilt 
\begin{equation}
\label{eq:diffCompoundFunction}
\gatdiff v = \gatdiff(G(u)) = G'(u)\gatdiff u
\end{equation}
wobei $G':\Gil\to\Hil$ die Ableitung von $G$ bzgl. $u$ und ein linearer Operator ist. Wenn man nun \eqref{eq:diffCompoundFunction} in \eqref{eq:diffInnerProduct} einsetzt erhält man 
\begin{equation}
 \gatdiff J = \langle \nabla_v J,G'\gatdiff u\rangle_\Hil \overset{\eqref{eq:adjointInnerProduct}}{=}  \langle G'^* \nabla_v J,\gatdiff u\rangle_\Gil \overset{n.V.}{=} \langle \nabla_u J,\gatdiff u\rangle_\Gil 
\end{equation}
wobei $G'^*$ der adjungierte Operator von $G'$ beschreibt. Damit ist 
\begin{equation}
\label{eq:adjointEssential}
\nabla_u J = G'^*\nabla_v J
\end{equation} 
Die Gleichung \eqref{eq:adjointEssential} stellt die Basis für die Nutzung der adjungierte Operatoren für die Datenassimilation dar. Sie bietet ein besonders effizienten Weg $\nabla_u J$ numerisch zu berechnen. Angewandt auf unser Problem wäre $u\mapsto v =G(u) $ eine Integration eines numerischen Modells. Aus einer Integrationsmethode, welche $G'^*w$ für ein gegebenes $w$ berechnen kann, kann nun aus $\nabla_v J$ mittels \eqref{eq:adjointEssential} einfach $\nabla_u J$ errechnet werden. 
% Wenn $J$ einfach gewählt wurde, lässt sich daraus $\nabla_v J$ ebenfalls einfach berechnen. 
Um $\nabla_u J$ zu erhalten, muss zuerst $v = G(u)$ berechnet werden, danach $\nabla_v J$ und schlussendlich wieder $\nabla_u J$ durch \eqref{eq:adjointEssential}.

\subsection{Berechnung des Gradienten}
Um vorherige Betrachtungen auf die Ableitung des Zielfunktionals \eqref{eq:costfunctional} anwenden zu können wird die Gâteaux Ableitung des Kostenfunktionals \eqref{eq:costfunctional} zu einem Anfangswert $v$ wie folgt gebildet
\begin{equation}
\label{eq:gatcost}
\begin{aligned}
 \gatdiff J(v)  &= \lim_{\tau\to 0} \frac{1}{\tau}\int_0^T H(x+\tau\gatdiff x)-H(x)~ dt\\
	    &= \lim_{\tau\to 0} \frac{1}{\tau}\int_0^T \int_0^1 \frac{d}{ds}H(x+s\tau\gatdiff x) ~ds~ dt\\
	    &= \lim_{\tau\to 0} \int_0^T \int_0^1 \nabla_x H(x+s\tau\gatdiff x)\cdot \frac{\tau \gatdiff x}{\tau} ~ds ~dt\\
	    &= \int_0^T \nabla_x H(x)\cdot \gatdiff x~ dt\\
	    &= \int_0^T \langle \nabla_x H(x), \gatdiff x \rangle dt\\  
\end{aligned}
\end{equation}
Dabei beschreibt $\nabla_x H(t)$ den Gradienten von $H(x,t)$ ausgewertet an der Stelle $(x(t),t)$ und $\gatdiff x$ die Gâteaux-Ableitung von $x$, also eine Störung. Diese ist definiert als die Lösung von
\begin{equation}
\label{eq:tlm}
\begin{aligned}
  \frac{d \gatdiff x}{dt} &= \lim_{\tau\to 0}\frac{F(x+\tau \gatdiff x)-F(x)}{\tau}\\
			 &= \frac{d F(x+\tau\gatdiff x)}{d\tau} \Bigg\rvert_{\tau=0}\\
			 &= F'(t)\gatdiff x
\end{aligned} 
\end{equation}

und wird als \textit{Tangent Linear Model}\footnote{Da es für viele englische Begriffe nur eine unzureichende deutsche Übersetzung gibt, werden sie in dieser Arbeit nicht übersetzt, da man sie in der Literatur besser unter dem englischen Namen findet.} bezeichnet. $F'(t)$ ist der Operator, der durch differenzieren von $F(x,t)$ nach $x$ ausgewertet an $x(t)$ entsteht. Da die gewöhnliche Differentialgleichung \eqref{eq:tlm} homogen und linear ist, hängt ihre Lösung linear vom Anfangswert $v$ ab und es gilt
\begin{equation}
\label{eq:resolvent}
 \gatdiff x(t) = R(t,0)v
\end{equation}

Hierbei ist $R(t,0)$ ein wohldefinierter linearer Operator. Dieser wird als \textit{State Transition Matrix} oder \textit{Resolvent} bezeichnet und wird ausführlich von Zadeh und Desoer in \cite[S. 339 ff.]{zadeh1976linear} beschrieben. Er besitzt die folgenden Eigenschaften
\begin{align}
  R(t,t) &= I \label{eq:resolventPropertiesA}\\
  \frac{\partial}{\partial t}R(t,t') &= F'(t)R(t,t') \text{ für alle } t,t>0\label{eq:resolventPropertiesB}
\end{align}
welche ebenfalls in \cite[S. 339 Theorem 4]{zadeh1976linear} eingeführt und bewiesen werden.
Nun kann das Differential des Kostenfunktionals \eqref{eq:gatcost} mittels des Resolventen \eqref{eq:resolvent} und deren adjungiertem Operator $R^*(t,0)$ umgeschrieben werden zu
\begin{equation*}
\begin{aligned}
 \gatdiff J &= \int_0^T \langle \nabla_x H(t), R(t,0)v\rangle dt \\
	    &= \int_0^T \langle R^*(t,0) \nabla_x H(t), v\rangle dt \\
	    &= \left\langle \int_0^T R^*(t,0) \nabla_x H(t) dt, v\right\rangle \\
\end{aligned}
\end{equation*}
und es ergibt sich wie in den Betrachtungen zu Gleichung \eqref{eq:adjointEssential} %TODO die Anfangswertbedinungen einheitlich bennen v -> \gatdiff u oder so
\begin{equation}
\label{eq:gradCostFunctional}
 \nabla_v J = \int_0^T R^*(t,0) \nabla_x H(t) dt
\end{equation}
Der adjungierte Operator $R^*(t,0)$ des Resolventen $R(t,0)$ wird durch die Lösung des adjungierten Tangent Linear Models von \eqref{eq:tlm} 
\begin{equation}
\label{eq:adjointtlm}
 -\frac{d \gatdiff'x}{dt} = F'^*(t)\gatdiff'x
\end{equation}
beschrieben, wobei $\gatdiff'x \in\Hil$ und $F'^*(t)$ die Adjungierte von $F'(t)$ ist. 
Sei $S(t,t')$ der Resolvent von \eqref{eq:adjointtlm} zwischen den Zeitpunkten $t$ und $t'$. Für zwei Lösungen $\gatdiff x$ und $\gatdiff' x$ des Tangent Linear Models \eqref{eq:tlm} und deren Adjungierte \eqref{eq:adjointtlm} ist das innere Produkt $\langle \gatdiff x,\gatdiff' x\rangle$ konstant, da das innere Produkt der Ableitungen nach $t$ verschwindet:
\begin{equation}
\begin{aligned}
 \frac{d}{dt}\langle \gatdiff x(t),\gatdiff' x(t)\rangle  &= \left\langle \frac{d \gatdiff x}{dt}(t) ,\gatdiff' x\right\rangle +\left\langle \gatdiff x,\frac{d\gatdiff ' x}{dt}(t)\right\rangle \\
 &= \langle F'(t)\gatdiff x(t),\gatdiff 'x(t)\rangle - \langle \gatdiff x(t),F'^*(t)\gatdiff' x(t)\rangle\\
 &= 0
\end{aligned}
\end{equation}
Daraus folgt unmittelbar, dass die Lösungen zweier Anfangswerte $y,y' \in \Hil$ die Gleichung
\begin{equation*}
\langle R(t',t)y,y'\rangle = \langle y,S(t,t')y'\rangle 
\end{equation*}
erfüllen, da die Lösung des Tangent Linear Models \eqref{eq:tlm} für die Anfangsbedingung $y$ am Zeitpunkt $t$ gerade den Wert $R(t',t)y$ zum Zeitpunkt $t'$ und die Lösung des adjungierten Tangent Linear Models \eqref{eq:adjointtlm} für die Anfangsbedingung $y'$ am Zeitpunkt $t'$ den Wert $S(t,t')y'$ zum Zeitpunkt $t$ annimmt. Da dies für alle $y,y'$ gilt, ist $S(t,t')$ der adjungierte Operator von $R(t',t)$.
Für den Gradienten des Kostenfunktionals \eqref{eq:gradCostFunctional} entsteht somit
\begin{equation}
\label{eq:gradCostFunctionalAdjoint}
 \nabla_v J = \int_0^T S(0,t) \nabla_x H(t) dt
\end{equation}
Um den Gradienten des Kostenfunktionals nun darstellen zu können benötigen wir die \textit{inhomogene adjungierte Gleichung} (oder auch \textit{inhomogenes adjungierte tangent linear model})
\begin{equation}
\label{eq:inhAdjEquation}
-d\gatdiff'x(t) = F'^*(t)\gatdiff'x - \nabla_x H(t)
\end{equation}
welche durch die Lösung 
\begin{equation}
\label{eq:solutionInhAdjEquation}
 \gatdiff'x(t) = \int_t^{t_1} S(t,\tau)\nabla_x H(\tau)d\tau
\end{equation}
mit $\gatdiff x(t_1)=0$ beschrieben ist.
Dass \eqref{eq:solutionInhAdjEquation} die inhomomgene adjungierte Gleichung \eqref{eq:inhAdjEquation} löst lässt sich mittels den Eigenschaften des Resolventen \eqref{eq:resolventPropertiesA} und \eqref{eq:resolventPropertiesB} zeigen. Durch Substituieren erhält man
\begin{equation*}
 \begin{aligned}
  \frac{d\gatdiff'x}{dt} &= \frac{d}{dt} \int_t^{t_1} S(t,\tau)\nabla_x H(\tau)d\tau \\
			 &= \frac{d}{dt} \int_t^{t_1} G(t,\tau)d\tau 
\end{aligned}
\end{equation*}
Durch Ableiten nach $t$ und der verallgemeinerten Leibniz Integral Formel (\ref{eq:genLeibnizIntRule}) folgt
\begin{equation*}
 \begin{aligned}
 \frac{d}{dt} \int_t^{t_1} G(t,\tau)d\tau  
			 &\overset{\eqref{eq:genLeibnizIntRule}}= G(t,t_1)\cdot 0 - G(t,t) + \int_t^{t_1} \frac{d}{dt}G(t,\tau) d\tau \\
			 &= -S(t,t)\nabla_x H(t) + \int_t^{t_1} \frac{d}{dt}S(t,\tau)\nabla_x H(\tau) d\tau \\
			 &\overset{\eqref{eq:resolventPropertiesA},\eqref{eq:resolventPropertiesB}}= -\nabla_x H(t) + \int_t^{t_1} F'^*(t)S(t,\tau)\nabla_x H(\tau) d\tau \\
			  &= -\nabla_x H(t) +F'^*(t) \int_t^{t_1} S(t,\tau)\nabla_x H(\tau) d\tau \\
			 &= -\nabla_x H(t) +F'^*(t) \gatdiff 'x(t) \\
 \end{aligned}
\end{equation*}
Die umgekehrte Richtung wird fast analog bewiesen; es gilt
\begin{equation*}
 -\frac{d\gatdiff 'x}{dt} = F'^*(t) \gatdiff'x - \nabla_x H(t)
			 = \frac{d}{dt} \int_t^{t_1} S(t,\tau) \nabla_x H(\tau) d\tau
\end{equation*}
Integration über $[t,t_1]$ liefert
\[
 \gatdiff 'x(t) -  \gatdiff 'x(t_1)  = \int_t^{t_1} S(t,\tau) \nabla_x H(\tau) d\tau
\]
Mit $ \gatdiff 'x(t_1) = 0$ und mit \eqref{eq:gradCostFunctionalAdjoint} folgt, dass $\nabla_v J = \gatdiff'x(0)$. Das bedeutet, dass sich der Gradient des Zielfunktionals mithilfe einer Rückwärtsintegration des adjungierten Modells berechnen lässt.
Genauer werden die Schritte in Abbildung \ref{alg:genCostFunctionalPseudo} benötigt, um den Gradienten des Zielfunktionals \eqref{eq:costfunctional} zu berechnen.
\begin{figure}
\begin{framed}
 \begin{enumerate}
 \item Setze $v$ als Anfangswert des Modells \eqref{eq:odemodel} und löse dieses über das Intervall $[0,T]$, speichere berechnete Werte $x(t_i)$ ab\\
 ($0= t_0<~ t_1<\ldots<t_l=T$, $l\in \N$)
 \item Setze $\gatdiff 'x(T) = 0$, integriere die inhomogene adjungierte Gleichung \eqref{eq:inhAdjEquation} rückwärts in der Zeit von $T$ bis $0$, berechne zu den Zeitpunkten $t_i$ den Gradienten $F'^*(t_i)$ und $\nabla_x H(t_i)$ aus den gespeicherten Werten $x(t)$ aus Schritt 1.
 \item $\nabla_v J = \gatdiff 'x(t_0)$
\end{enumerate}
\end{framed}
\caption{Berechnung der Jacobimatrix des Kostenfunktionals $J$}
\label{alg:genCostFunctionalPseudo}
\end{figure}

% Übersetzt in Pseudocode lautet der Algorithmus
%  \begin{algorithm}[H]
%  \algrenewcommand{\algorithmiccomment}[1]{\hfill{\scriptsize #1}}
%  \caption{\texttt{PlanC::calc\_kink\_partials}}
%  \label{alg:kinkPartials}
%  \begin{algorithmic}[1]
%  \Function{jac\_data\_assimilation}{$f,$}
%  	\State $xCalc \gets solve_ode()$
%  	\State $\bar{A} \gets 0 $, $\hat{A} \gets 0$
% 	\State $d\gets \frac{d}{\|d\|}\cdot \|\xhat - \xcheck\|$ \Comment{Normalize direction}
%  \Until{$\hat{\tau} \geq 1$	}
%  \State \Return $[\bar{A}, \hat{A}]$;
%  \EndFunction
%  \end{algorithmic}
%  \end{algorithm}
% 
% TODO: ALGORITHMUS HIER?

\section{Optimierungsmethoden}

Nun, da ein numerischer Weg gefunden wurde, $\nabla_v J$ effizient zu berechnen, stellt die Optimierung des Zielfunktional das letzte Problem dar, welchem wir uns annehmen müssen. Das Ausgangsproblem besteht darin, eine reellwertigen, differenzierbaren Funktion J
\begin{equation}
\label{eq:minProblem}
 \min_{x_0} J(x_0) 
\end{equation}
zu minimieren. Dies ist ein unrestringiertes Optimierungsproblem. 

\subsection{Grundlagen}
Im folgenden sei vorausgesetzt, dass für ein $\tilde x\in D$ die \textit{Niveaumenge}
 \begin{equation}
 \label{eq:niveauset}
  N(J,J(\tilde x)) = \left\{ x\in D \vert J(x)\leq J(\tilde x)\right\}
 \end{equation}

  

 von $J$ in $x\in \R^n$ kompakt sei. Unter dieser Voraussetzung existiert nach dem Satz von Weierstraß ein $\bar x \in N(J,J(\tilde x))$ mit 
 \[
  J(\bar x) \leq J(x) \forall x\in N(J,J(\tilde x))
 \]
 und damit ist für $x\in D\backslash N(J,J(\tilde x))$: $J(x)>J(\tilde x)> J(\bar x)$. (vgl. \cite[Satz 1.2.2]{alt2002nichtlineare})
 

Zur Charakerisierung von Lösungen von des Problemes \eqref{eq:minProblem} ist der im folgenden erläuterte Satz über notwendige Bedingungen (vgl. \cite[vgl. Satz 3.1.1 ff.]{alt2002nichtlineare}) hilfreich:
\begin{theorem}[Notwendige Bedingung erster Ordnung] 
\label{thm:optnotbed}
 Die Zielfunktion $J$ sei in $x\in D$, $D\subset \R^n$ differenzierbar. Ist $\bar x$ lokales Minimum von \eqref{eq:minProblem}, dann gilt
 \[
  \nabla J(\bar x)^\tr d \geq 0 \quad \forall d\in \R^n
 \]
 Wenn $d\in \R^n$ ist $(-d)\in \R^n$ und damit $\nabla J(\bar x)^\tr (-d) =  - \nabla J(\bar x)^\tr d  \geq 0$. Es folgt also
 \[
  \nabla J(\bar x)  =0 \in \R^n
 \]
\end{theorem}

Dieses Resultat wird zur Konstruktion von Optimierungsverfahren, insbesondere Abstiegsverfahren, verwendet. 
Grundlegend dafür ist die Erkenntnis, dass falls $J$ differenzierbar und eine Abstiegsrichtung $d\in \R^n$ mit 
\[
\nabla J(x)^\tr d<0 
\]
gegeben ist, existiert immer ein $\bar \sigma>0$ mit $J(x+\sigma d)< J(x)$ für alle $\sigma \in (0,\bar \sigma)$ (\cite[vgl. Satz 4.1.1]{alt2002nichtlineare})


%Bevor wir uns dieser annehmen, werden grundsätzliche Fragen zur Wahl der Suchrichtung und Schrittweite betrachtet. 

% Unser Ziel besteht darin, motiviert durch das Resultat aus Theorem \ref{thm:optnotbed}, für  
% (\cite[vgl. Satz 4.1.1]{alt2002nichtlineare}) 

 Ein Vektor $d$ heißt Abstiegsrichtung von $J$ im Punkt $x$, wenn $\nabla J(x)^\tr d<0$. Beispielsweise wird im Verfahren des steilsten Abstiegs gerade $d=- \nabla J(x)$ als Abstiegsrichtung verwendet, da 
\[
\nabla J(x)^\tr d = \nabla J(x)^\tr (-\nabla J(x)) = - \|\nabla J(x)\|^2 <0                                                                                                                                                                                                                                                                        \]
Ein allgemeines Abstiegsverfahren mit Schrittweitensteuerung wird ebenfalls in \cite[S. 69, Verfahren 4.1.4]{alt2002nichtlineare} gegeben und ist in Abbildung \ref{alg:genSteepestDescent} beschrieben.
\begin{figure}[H]
\begin{framed}
 \begin{enumerate}
  \item Wähle einen Startpunkt $x^{(0)}\in \R^n$ und setze $k:=0$
  \item Ist $\nabla f(x^{(k)})=0_n$: Stopp
  \item Berechne eine Abstiegsrichtung $d^{(k)}$ und eine Schrittweite $\sigma_k>0$, so dass
  \[
   f(x^{(k)} + \sigma_k d^{(k)} < f(x^{(k)}))
  \]
  ist und setze $x^{(k+1)} = x^{(k)}+\sigma_k d^{(k)}$
  \item Setze $k:=k+1$ und gehe zu 2.
 \end{enumerate}
\end{framed}
\caption{Allgemeines Abstiegsverfahren mit Schrittweitensteuerung}
\label{alg:genSteepestDescent}
\end{figure}

\subsection{Effiziente Schrittweiten}
Um dem Ziel der Bestimmung effizienter Schrittweiten näher zu kommen, müssen wir fordern, dass für die Folge $x^{(k)}$ mit jedem weiteren Schritt gegen einen stationären Punkt konvergiert, also dass  
\begin{equation}
\label{eq:optstepsizegradtozero}
 \nabla f(x^{(k)})\to 0 \quad \text{für }k\to \infty
\end{equation}
gilt.
Um dies zu erreichen wird im Folgenden das Prinzip des hinreichenden Abstiegs formuliert (\cite[Def. 4.4.2]{alt2002nichtlineare}):
\begin{definition}[Prinzip des hinreichenden Abstiegs]
\label{def:sufficientdescent}
 Seien $x\in N(J,J(x^{(0)}))$ und $d\in \R^n$ mit $\nabla_u J(x)^\tr d<0$ gegeben. Eine Schrittweite $\sigma$ erfüllt das \textit{Prinzip des hinreichenden Abstiegs}, falls
 \begin{equation}
 \label{eq:armijo1}
  f(x+\sigma d) \leq f(x) + c_1\sigma \nabla f(x)^\tr d
 \end{equation}
 und 
 \begin{equation}
\label{eq:armijo2}
 \sigma \geq -c_2 \frac{\nabla J(x)^\tr d}{\|d\|^2}
 \end{equation}


mit von $x$ und $d$ unabhängigen Konstanten $c_1>0$, $c_2>0$ gilt. Eine Schrittweite $\sigma$ heißt \textit{effizient}, falls
\[
 f(x+\sigma d) \leq f(x) - c\left( \frac{\nabla J(x)^\tr d}{\|d\|}\right)^2
\]
mit einer von $x$ und $d$ unabhängigen Konstanten $c>0$ gilt.
\end{definition}
Die erste Bedingung stellt sicher, dass sich der neue Funktionswert $f(x+\sigma d)$ unterhalb der von $x$ in Abstiegsrichtung $d$ aufgespannten Geraden befindet. 
Die zweite Bedingung sichert, dass die Schrittweite $\sigma$ in Bezug zu $\nabla J(x)^\tr d$ nicht zu schnell gegen $0$ geht.

Falls die Voraussetzung \eqref{eq:niveauset} erfüllt ist und wir effiziente Schrittweiten benutzen ist
\[
 \frac{\nabla f(x^{(k)})^\tr d^{(k)}}{\|d^{(k)}\|} \to 0 \quad \text{für }k\to \infty
\]
erfüllt. Andersherum ist für $\nabla f(x^{(k)})^\tr d^{(k)}<0$
\[
 0 \leftarrow \frac{\nabla f(x)^{(k)} d^{(k)}}{\|d\|} = \frac{\nabla f(x)^{(k)} d^{(k)}}{\|\nabla f(x^{(k)})\|\|d\|}\cdot \|\nabla f(x^{(k)})\| = \beta_k \|\nabla f(x^{(k)})\|
\]
für $\beta_k<c<0$ für eine Konstante $c$ erfüllt. Damit folgt Bedingung \eqref{eq:optstepsizegradtozero}. Suchrichtungen, für die diese Bedingung gelten, heißen \textit{gradientenbezogen} (\cite[Def. 4.4.4]{alt2002nichtlineare}).

Falls $x\in N(f,f(x^{(0)}))$ erfüllt ist, heißt die Richtung $d\in \R^n$ \textit{gradientenbezogen in x}, wenn
 \[
  -\nabla f(x)^\tr d\geq c_3\|\nabla f(x)\| \|d\|
 \]
mit einer von $x$ und $d$ unabhängigen Konstante $c_3>0$.

Die Richtung $d$ heißt \textit{streng gradientenbezogen in $x$}, wenn zusätzlich 
\[
 c_4\|\nabla f(x)\| \geq \|d\| \geq \frac{1}{c_4}\|\nabla f(x)\| 
\]
gilt.

Falls die Bedingung \eqref{eq:niveauset} erfüllt ist, die Suchrichtungen aus dem allgemeinen Abstiegsverfahren \ref{alg:genSteepestDescent} gradientenbezogen in $x^{(k)}$ und die Schrittweiten $\sigma_k$ effizient sind und stoppt das Verfahren nicht nach endlich vielen Schritten, dann gilt $\nabla f(x^{(k)})\to 0$ für $k\to \infty$. Weiter hat die Folge $\{x^{(k)}\}$ mindestens einen Häufungspunkt und für jeden solchen Punkt $\tilde x$ gilt $\nabla f(\tilde x) = 0$ (\cite[Satz 4.4.9]{alt2002nichtlineare}).
% TODO eindige Nullstelle oder mehrere Nullstellen?

Falls zusätzlich $d$ eine streng gradientenbezogene Suchrichtung in $x^{(k)}$, die Schrittweitenfolge $\sigma_k$ beschränkt, die Menge 
$$M = \{\tilde x\in N(f,f(x^{(0)}))|\nabla f(\tilde x)=0\}$$ endlich ist und das Verfahren nicht nach endlich vielen Schritten stoppt, dann konvergiert die Folge $\{x^{(k)}\}$ gegen eine Nullstelle von $\nabla f$.

Hat $f$ genau einen stationären Punkt $\tilde x \in N(f,f(x^{(0)}))$ und das allgemeine Abstiegsverfahren stoppt nicht nach endlich vielen Schritten,dann konvergiert die Folge $\{x^{(k)}\}$ gegen $\tilde x$.
 
Eine Möglichkeit, die sich zur Schrittweitenbestimmung anbietet besteht darin, die Schrittweite durch Lösen eines eindimensionalen Optimierungsproblems
\[
 \min_{s\geq 0} J(x+sd)
\]
zu bestimmen. Ist $x\in N(J,J(x^{(0)}))$ und $d$ so gewählt, dass $\nabla J(x)^\tr d <0$, so hat die Funktion $\nabla J(x+sd)^\tr d$ eine kleinste, positive Nullstelle $\sigma_E>0$. Für die exakte Schrittweite gilt mit $H = J''(x)$ (\cite[Gleichung (4.5.5)]{alt2002nichtlineare})
\[
 \sigma_E = -\frac{\nabla J(x)^\tr d}{d^\tr H d}
\]
Diese Nullstelle ist eindeutig, falls die Zielfunktion $J$ konvex ist. Für ein quadratisches Optimierungsproblem wird die exakte Schrittweite benutzt. In unserem Fall muss man sich jedoch mit einer Näherung zufrieden geben, da die Konvexität des Kostenfunktionals nicht sichergestellt werden kann. 
 
Motiviert aus dem Prinzip des hinreichenden Abstiegs aus Definition \ref{def:sufficientdescent} ergibt sich das Armijo Verfahren (\cite[Verfahren 4.5.4]{alt2002nichtlineare}), um eine effiziente Schrittweite $\sigma_A$ zu erhalten.
% \begin{figure}[H]
% \begin{framed}
%  Gegeben seien Konstante $0<c_1<1$, $0<c_2$ und $0<\beta_1\leq \beta_2 <1$ unabhängig von $x$ und $d$.
%  \begin{enumerate}
%   \item Wähle eine Start-Schrittweite 
%   \[
%    \sigma_0 \geq -c_2 \frac{\nabla f(x)^\tr d}{\|d\|^2}
%   \]
%   und setze $j:=0$
%   \item Ist die Bedingung \eqref{eq:armijo1} erfüllt, d.h. gilt
%   \[
%    f(x+\sigma_j d)\leq f(x)+ c_1\sigma_j \nabla f(x)^\tr d
%   \]
%   dann setze $\sigma_A = \sigma_j$ und stoppe das Verfahren
%   \item Wähle $\sigma_{j+1}\in [\beta_1\sigma_j,\beta_2\sigma_j]$
%   \item Setze $j:=j+1$ und gehe zu 2.
%  \end{enumerate}
% \end{framed}
% \caption{Armijo Verfahren zur Schrittweitensteuerung}
% \end{figure}
Den Beweis der Konvergenz ist in  \cite[Satz 4.5.5]{alt2002nichtlineare} dargelegt.

Ein weiteres Verfahren stellt die sogenannte \textit{Wolfe Powell Methode} dar, welche zusätzlich zu der Bedingung \eqref{eq:armijo1}
\begin{equation}
 f(x+\sigma d) \leq f(x) + c_1\sigma \nabla f(x)^\tr d
\end{equation}

welche den hinreichenden Abstieg liefert, die Schrittweite durch die Forderung
\begin{equation}
\label{eq:wolfe2}
 \nabla f(x+\sigma d)^\tr d\geq \beta \nabla f(x)^\tr d
\end{equation}
mit $0<c_1<\beta<1$ nicht zu klein werden lässt. Das bedeutet, dass die Steigung an der potentiellen Stelle $x+\sigma d$ abnimmt, damit sichergestellt wird, dass wir uns einem Minimum nähern, siehe Abbildung \ref{fig:powell}. 

\begin{figure}
\centering
\input{img/powell.tikz}
\caption{Powell Schrittweitensteuerung}
\label{fig:powell}
\end{figure}
Wenn diese beiden Forderungen, $x\in N(f,f(x^{(0)}))$ und $d\in R^n$ mit $\nabla f(x)^\tr d<0$ erfüllt sind und $0<\delta<\beta<1$,$\delta =c_1$ gegeben, dann existiert mindestens eine Schrittweite $\sigma_p$, sodass sie den beiden Abstiegskriterien \eqref{eq:armijo1} und \eqref{eq:wolfe2} genügt und für alle $\sigma_p$
\[
 \sigma_p \geq \frac{1-\beta}{L}\frac{\nabla f(x)^\tr d}{\|d\|^2}
\]
gilt (\cite[Satz 4.5.8.]{alt2002nichtlineare}).

Um diese beiden Bedingungen numerisch zu berechnen definiert man
\begin{equation}
\begin{aligned}
 G_1(\sigma)&=
 \begin{cases}
 1,& \sigma=0\\
 \frac{f(x+\sigma d)-f(x)}{\sigma \nabla f(x)^\tr d}, & \text{sonst}
 \end{cases} \\
 G_2(\sigma) &= \frac{\nabla f(x+\sigma d)^\tr d}{\nabla f(x)^\tr d}
 \end{aligned}
\end{equation}
und erhält das Wolfe - Powell Verfahren in Abbildung \ref{alg:wolfePowell}.

\begin{figure}
\begin{framed}
Vorgegeben seien die Konstanten $0<\delta<\beta<1$
 \begin{enumerate}
  \item Wähle eine Start-Schrittweite $\sigma_0$ und setze $j:=0$
  \begin{enumerate}
   \item Ist $G_1(\sigma_0)\geq \delta$ und $G_2(\sigma_0)\leq \beta$, dann setze $\sigma_p=\sigma_0$ und Stoppe das Verfahren
   \item Ist $G_1(\sigma_0)\geq \delta$ und $G_2(\sigma_0)> \beta$, dann setze $a_0=\sigma_0$ und $b_0=2^l\sigma_0$, mit minimalem $l\in \N_0$, sodass $G_1(b_0)<\delta$, gehe zu 2)
   \item Ist $G_1(\sigma_0)\leq \delta$, dann setze $b_0=\sigma_0$ und $a_0=2^{-l}\sigma_0$ mit minimalem $l\in \N$, sodass $G_1(a_0)\geq\delta$ und $G_2(a_0)>\beta$, gehe zu 2)
  \end{enumerate}
  \item Berechne den Intervallmittelpunkt $\sigma_j = 0.5\cdot (a_j+b_j)$
  \begin{enumerate}
    \item Ist $G_1(\sigma_j)\geq \delta$ und $G_2(\sigma_j)\leq \beta$, dann setze $\sigma_p=\sigma_j$ und Stoppe das Verfahren
    \item Ist $G_1(\sigma_j)\geq \delta$ und $G_2(\sigma_j)> \beta$, dann setze $a_{j+1}=\sigma_j$ und $b_{j+1}=b_j$, gehe zu 3)
    \item Ist $G_1(\sigma_0)\leq \delta$, dann setze $a_{j+1}=a_j$ und $b_{j+1}=\sigma_j$, gehe zu 3)
  \end{enumerate}
  \item Setze $j:=j+1$, gehe zu 2)
 \end{enumerate}
\end{framed}
\caption{Wolfe Powell Verfahren zur Schrittweitensteuerung}
\label{alg:wolfePowell}
\end{figure}

Für die endgültige Optimierung unseres Zielfunktionals $J$ haben wir eine notwendige Bedinung hergeleitet und daraus Verfahren zur Schrittweitensteuerung gewonnen. Als letzten Punkt müssen wir diese nur noch korrekt zusammen anwenden
\subsection{Abstiegsverfahren}
Der allgemeine Algorithmus zur Optimierung unrestringierter Optimierungsprobleme wurde durch das allgemeine Abstiegsverfahren  \ref{alg:genSteepestDescent} gegeben. Die Abstiegsmethoden unterscheiden sich nun durch die Wahl einer geeigneten Suchrichtung. 
Wählt man als Suchrichtung $d = -\nabla J(x^{(k)})$ so ergibt sich das \textit{Gradientenverfahren} oder \textit{Methode des steilsten Abstiegs}
% \begin{figure}[H]
% \begin{framed}
% \begin{enumerate}
%  \item Wähle Anfangspunkt $x^{(0)}$ und setze $k:=0$
%  \item Überprüfe $\nabla J(x^{(k)}) == 0$?: Stopp
%  \item Setze als Suchrichtung $d = - \nabla J(x^{(k)})$, berechne effiziente Schrittweite $\alpha_k$ und setze $x^{(k+1)} = x^{(k)}+ \alpha_k d^{(k)}$
%  \item Setze $k:= k+1$ und gehe zu 2.
% \end{enumerate} 
% \end{framed}
%  \caption{Methode des steilsten Abstiegs}
% \end{figure}

Sie besitzt eine lineare Konvergenzordnung, da für eine exakte Schrittweite $\sigma_E$ gilt:
\[
 0 = \frac{\partial }{\partial \sigma} J(x^{(k)} + \sigma d^{(k)}) \Big|_{\sigma = \sigma_k} = \nabla J(x^{(k+1)})^\tr d^{(k)} = - \left( d^{k+1}\right)^\tr d^{(k)}
\]
Daher gilt also
\[
 d^{(k+1)}~\bot ~d^{k} ~ \forall k \in \N
\]
Ein verbesserte Wahl der Suchrichtung $d$ bietet das BFGS-Verfahren (\cite[Verfahren 4.8.11]{alt2002nichtlineare})
\begin{figure}[H]
\begin{framed}
\begin{enumerate}
 \item Wähle Anfangspunkt $x^{(0)}$, eine symmetrisch positiv definite Matrix $A^{(0)}$ und setze $k:=0$
 \item Überprüfe $\nabla J(x^{(k)}) == 0$?: Stopp
 \item Berechne $d^{(k)} = -\left( A^{(k)} \right)^{-1} \nabla J(x^{(k)})$, wähle eine effiziente Schrittweite $\sigma_k$, berechne 
 \[
 \begin{aligned}
  x^{(k+1)} &= x^{(k)} + \sigma_k d^{(k)}, \\ s^{(k)} &= x^{(k+1)} - x^{(k)},\\ y^{(k)} &= \nabla J(x^{(k+1)})- \nabla J(x^{(k)})
 \end{aligned}
 \]
 \item Setze $k:= k+1$ und gehe zu 2.
\end{enumerate} 
\end{framed}
 \caption{BFGS - Verfahren}
 \label{alg:bfgs}
\end{figure}
Wobei die Matrix $A$ durch die BFGS-Updateformel 
\[
 A^{(k+1)} = A^{(k)} - \frac{A^{(k)}s^{(k)}(A^{(k)}s^{(k)})^\tr}{(s^{(k)})^\tr A^{(k)}s^{(k)}} + \frac{y^{(k)} (y^{(k)})^\tr}{(y^{(k)})^\tr s^{(k)}}
\]
errechnet wird.
\subsubsection{Abbruchbedingungen}
Der Optimierungsprozess bei der Data Assimilation wird abgebrochen, falls einige der folgenden Kriterien zu einer gegebenen Toleranz \texttt{tol} erfüllt sind
\begin{itemize}
 \item Änderung der Funktion zwischen zwei Iterierten
 \[
  |J(x_{k+1}) - J(x_{k})| < tol
 \]
\item Änderung der Zustandsvariable
\[
 \|x_{k+1} - x_{k}\|<tol
\]
\item Die Norm des Gradienten
\[
 \|\nabla J(x_k)\|<tol
\]
\item Das Verhältnis des Gradienten am Anfangs und am jetzigen Wert
\[
 \frac{\|\nabla J(x_k)\| }{\|\nabla J(x_0)\|}<tol
\]


\end{itemize}


\section{Zusammenfassung}
In den vorherigen Kapiteln wurde beschrieben, welche Schritte notwendig sind, um die variationelle Datenassimilation durchzuführen.
Ziel ist es, das Minimierungsproblem \eqref{eq:bolzaProblem} zu lösen. Dazu wird auf das Kostenfunkional $J(x)$ ein Optimierungsverfahren angewandt, um ein Extremum zu finden. Um dies tun zu können benötigt man den Gradienten $\nabla J$, welcher durch die Rückwärtsintegration der adjungierten Gleichung des Tangent Linear Models \eqref{eq:adjModel} berechnet wird. Die Integration der ODEs wird durch numerische Verfahren, in unserem Fall durch die implizite Mittelpunktsregel (siehe Tabelle \ref{tab:rungekutta}), bewerkstelligt. Der große Vorteil dieses Verfahrens liegt darin begründet, dass die Berechnung des Gradienten $\nabla J$ nur ein weniges Vielfaches der Zeit einer Funktionsauswertung von $J$ in Anspruch nimmt. 

% Sämtliche Theorie, welche beschrieben wurde, gilt nur für den Fall, dass die rechte Seite der Evolutionsgleichung \eqref{eq:odemodel} glatt ist, also dass mindestens $F\in C^1(\R^n)$ gilt. Für den Fall, dass dem nicht so ist, werden im Folgenden Methoden vorgestellt, die versuchen, diese Unglattheiten mit in die Berechnung einzubeziehen.

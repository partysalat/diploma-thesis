\chapter{Datenassimilation}
\section{Problemstellung}
Die 4D variationelle Datenassimilation ist eine Methode, die im Zusammenhang mit hyperbolischen partiellen Differentialgleichungen steht, wie z.B. der Wellengleichung. Ziel ist es durch Steuerungsparameter, wie etwa Anfangswerte zum Zeitpunkt $t_0$, den Abstand eines Modells gegenüber der in der Zeit gemessenen Observierungsparameter minimal werden zu lassen. 

Um diese Methode herzuleiten folgen wir der Herangehensweise von Talagrand in \cite{talagrand1987variational} und nehmen zuerst die Evolutionsgleichung
\begin{equation}
\label{eq:odemodel}
 \frac{dx}{dt} = F(x)\quad \text{mit} \quad x(0) = x_0 \quad \text{und}\quad F:\R^n\to \R^n
\end{equation}
  
welche eine Gewöhnliche Differentialgleichung beschreibt. $x$ ist dabei die zeitabhängige Zustandsvariable aus dem Hilbertraum $\R^n$, welche die Entwicklung des Systems zu einem Zeitpunkt $t\in \R$ beschreibt. 
$x_0 \in \R^n$ sei der Anfangswert, welcher gleichzeitig der Steuerungsparameter ist.
Die Observierungsparameter $\xobs$ sind diskrete Werte, welche Orts - und Zeitabhängig und über ein Interval $[0,T]$ verteilt sind. Da $\xobs$ diskret ist, wird eine Projektion $C:\Xstate\to \Xobs$ benötigt, welche $x$ aus dem Zustandsraum $\Xstate$ in den Observierungsraum $\Xobs$ abbildet. Üblicherweise ist diese Funktion eine Auswertungsfunktion von $x$ an den Stellen $\tobs$.

Als Kostenfunktional dient die $L^2$ - Norm der Differenz der Lösung $x$ von \eqref{eq:odemodel} zu $\xobs$ über ein gegebenes Zeitinterval $[0,T]$
\begin{equation}
\label{eq:costfunctional}
 J(x_0) = \frac{1}{2}\int_0^T H(x(t),t)dt= \frac{1}{2}\int_0^T \|C\cdot x(V)-\xobs\|^2dt
\end{equation}
Die skalarwertige Funktion $J$ ist damit jene Funktion, die das Maß zwischen der Lösung $x$ und den Observierungsparametern $\xobs$ darstellt.
Man beachte, dass das Zielfunktional nur abhängig vom Anfangswert $x_0$ ist. Das Ziel besteht darin, $x_0 = x_0^*$ zu finden, sodass
\[
 J(x_0^*) = \inf_{x_0} J(x_0) 
\]
minimiert wird. Die Grundlage zur Minimierung des Kostenfunktionals ist zunächst die Lösungstheorie zu gewöhnlichen Differentialgleichungen.

\section{Gewöhnliche Differentialgleichungen}
Eine Gleichung der Form \eqref{eq:odemodel} wird eine \textit{Gewöhnliche Differentialgleichung erster Ordnung} genannt. 
In der nachfolgend betrachteten Theorie sowie in der Implementation der Verfahren in dieser Arbeit werden ausschließlich autonome Gewöhnliche Differentialgleichungen erster Ordnung betrachtet, da sich sämtliche Gewöhnliche Differentialgleichungen in diese Form umschreiben lassen.
Falls nämlich eine Differentialgleichung n-ter Ordnung der Form 
\[
 \frac{d^n x}{dt^n}= F\left(t;x,\frac{dx}{dt},\ldots,\frac{d^{n-1} x}{dt^{n-1}}\right)
\]
mit $F$ differenzierbar, gegeben ist, ist wohlbekannt, dass sie sich durch Hinzufügen zusätzlicher Variablen in ein Differentialgleichungssystem erster Ordnung überführen lässt (\cite[S. 105]{arnold2001grundbegriffe}), mittels
\[
 \dot x_1 = x_2 \quad ,\ldots,\quad \dot x_{n-1} = x_n, \quad  \dot x_n = F(t;x_1,\ldots,x_{n-1})
\]
Durch die Einführung einer weiteren Variablen $x_0 = t$ und Gleichung $\dot x_0=1$ lässt sich die gegebene ODE autonom, also die rechte Seite $F$ unabhängig von der Zeit $t$, schreiben.

Die Existenz und Eindeutigkeit von Lösungen wird durch den Satz von Picard-Lindelöf beschrieben, der die Grundlage zur Lösungstheorie Gewöhnlicher Differentialgleichungen bildet. Dieser wird beispielsweise in \cite{teschl2012ordinary} bewiesen und lautet wie folgt 
\begin{theorem}[Picard-Lindelöf]
 Sei $F\in C(U,\R^n)$, wobei $U$ eine offene Teilmenge von $\R^{n+1}$ ist und $(t_0,x_0)\in U$. Falls $F$ im zweiten Argument lokal Lipschitzstetig und gleichmäßig stetig im ersten Argument ist, dann existiert eine eindeutige lokale Lösung $\bar x(t)\in C^1(I)$ des Anfangswertproblems \eqref{eq:odemodel}, wobei $I$ ein Interval um $t_0$ ist.
\end{theorem}





Bei den Optimierungsmethoden, welche wir betrachten, benötigt man daher den Gradienten der zu minimierenden Funktion $J$.
\section{Adjungierte Operatoren}
Für höhere Dimensionen ist die Bestimmung dieses Gradienten jedoch auf klassischem Weg numerisch sehr komplex. Dazu würde man jede Komponente unseres Systems \eqref{eq:odemodel} stören, das gestörte Modell in jeder Komponente integrieren und das Kostenfunktional dieser ausrechnen. Aus der Störung würde sich der Gradient $\partial J/\partial x_0$ ergeben. Dies ist sehr ineffizient. Als effiziente Alternative hat sich die Anwendung adjungierter Gleichungen erwiesen. Mit ihrer Hilfe kann die numerische Komplexität der Berechnung des Gradienten auf ein weniges Vielfaches des integrierens der Evolutionsgleichung \eqref{eq:odemodel} vermindert werden.

Eine allgemeine Einführung zur Theorie von adjungierten Gleichungen wurde beispielsweise von Cacuci \cite{cacuci1981sensitivity} gegeben, während Talagrand in \cite{talagrand1987variational} adjungierte Operatoren auf Hilberträume einschränkt und mit diesen die Datenassimilation einführt.
Für die folgenden Betrachtungen sind Hilberträume von besonderer Wichtigkeit. Sämtliche Lösungstheorie sowohl bei gewöhnlichen als auch bei partiellen Differentialgleichungen basieren auf den speziellen Eigenschaften dieser Räume.

Ein Hilbertraum ist ein reller oder komplexer Vektorraum mit einem Skalarprodukt, der bzgl. der vom Skalarprodukt induzierten Norm vollständig ist. Da $\R$ vollständig ist, ist jeder endlichdimensionale Vektorraum versehen mit einem Skalarprodukt vollständig. In der numerischen Praxis sind damit sämtliche folgenden Schritte valide. 
Ein Ableitungsbegriff auf Hilberträumen ist die sogenannte Gâteaux Ableitung.
\begin{definition}[Gâteaux Ableitung]
 Seien $X$ und $Y$ Banachräume, $U \subset X$ offen und $F:X\to Y$. Das Gâteaux Differential $\gatdiff F(u;\psi)$ von F an $u\in U$ in Richtung $\psi\in X$ ist definiert als
 \[
  \gatdiff F(u;\psi) = \lim_{\tau \to 0} \frac{F(x+\tau \psi) - F(x)}{\tau} = \frac{d}{d\tau} F(u+\tau\psi)\biggr\rvert_{\tau = 0}\quad \forall \psi \in X
 \]
 falls der Grenzwert existiert. Existiert der Grenzwert für alle $\psi\in X$, dann heißt $F$ Gâteaux-Differenzierbar in $u$.
 Falls $X$ und $Y$ endlichdimensional sind, entspricht das Konzept der Gâteaux Ableitung der der Richtungsableitung.
\end{definition}
Die folgende Definition der Adjungierten Operatoren und Proposition von Hilberträumen sind besonders nützlich für nachfolgende Betrachtungen.
\begin{definition}[Adjungierte Operatoren]
Sei $\Gil$ ein anderer Hilbertraum mit Innenprodukt $\langle \cdot,\cdot \rangle_\Gil$ und $L$ ein stetiger linearer Operator $L:\mathcal{G}\to \Hil$. Dann existiert ein eindeutiger stetiger linearer Operator $L^*:\Hil\to\Gil$, sodass für alle $u\in \Gil$ und $v\in \Hil$ gilt
\begin{equation}
\label{eq:adjointInnerProduct}
\langle v,Lu\rangle_\Hil =  \langle L^*v,u \rangle_\Gil
\end{equation}
$L^*$ heißt der \textit{adjungierte Operator} von $L$ (vgl. \cite[Definition V.5.1]{werner2007funktionalanalysis}). Im Falle das $\Hil$ und $\Gil$ endlichdimensional und durch orthonormale Koordinaten beschrieben werden kann, ist bekannt, dass  $L^*$ gerade die transponierte Matrix von $L$ ist.
% , da $\langle x,L^*y\rangle = \langle Lx,y\rangle =(Lx)^\tr y  = x^\tr L^\tr y= \langle x,L^\tr y\rangle  $
\end{definition}
Die Gâteaux Ableitung einer differenzierbaren Funktion ergibt sich als Richtungsableitung (vgl. \cite[Example 9.2.4]{debnath2005hilbert})
\begin{proposition}[Gâteaux Ableitung differenzierbarer Funktionen]
\label{prop:adjoints}
Sei $\Hil$ ein Hilbertraum mit Skalarprodukt $\langle \cdot,\cdot \rangle_\Hil$ und $v:\Hil \to \R,~ v\mapsto J(v)$ eine einmal stetig differenzierbare skalare Funktion definiert auf $\Hil$. Das Gâteaux Differential $\gatdiff J$ von $J$ kann an jedem Punkt von $\Hil$ über das Gâteaux Differential $\gatdiff v$ von $v$ ausgedrückt werden als
 \begin{equation}
 \label{eq:diffInnerProduct}
  \gatdiff J(v;\gatdiff v) = \langle \nabla_v J, \gatdiff v\rangle_\Hil
 \end{equation}
 $\nabla_v J$ ist hierbei der eindeutige Gradient von $J$ in Richtung $v$ an der Stelle $x$, welche zur Übersichtlichkeit weggelassen wurde. Wenn $\Hil$ endlichdimensional und durch orthonormale Koordinaten $v_i$ beschrieben ist, dann sind die Komponenten von $\nabla_v J$ gerade der Vektor der partiellen Ableitung von $J$ nach $v_i$, also $\partial J/\partial v_i$.
\end{proposition}


Seien $\Hil,~\Gil$ und $J$ wie in Proposition \ref{prop:adjoints} eingeführt. Betrachtet man jetzt eine Funktion $u:\Gil \to \Hil, ~u\mapsto v = G(u)$, G differenzierbar, so folgt, dass sich $J(v) = J(G(u))$ zu einer zusammengesetzte Funktion von $u$ ergibt. Nun ist 
\begin{equation}
\label{eq:diffCompoundFunction}
\gatdiff v = \gatdiff(G(u)) = G'(u)\gatdiff u
\end{equation}
wobei $G':\Gil\to\Hil$ die Ableitung von $G$ bzgl. $u$ und ein linearer Operator ist. Wenn man nun \eqref{eq:diffCompoundFunction} in \eqref{eq:diffInnerProduct} einsetzt erhält man 
\begin{equation}
 \gatdiff J = \langle \nabla_v J,G'\gatdiff u\rangle_\Hil \overset{\eqref{eq:adjointInnerProduct}}{=}  \langle G'^* \nabla_v J,\gatdiff u\rangle_\Gil \overset{n.V.}{=} \langle \nabla_u J,\gatdiff u\rangle_\Gil 
\end{equation}
wobei $G'^*$ der adjungierte Operator von $G'$ beschreibt. Damit ist 
\begin{equation}
\label{eq:adjointEssential}
\nabla_u J = G'^*\nabla_v J
\end{equation} 
Die Gleichung \eqref{eq:adjointEssential} stellt die Basis für die Nutzung der adjungierte Operatoren für die Datenassimilation dar. Sie bietet ein besonders effizienten Weg $\nabla_u J$ numerisch zu berechnen. Angewandt auf unser Problem wäre $u\mapsto v =G(u) $ eine Integration eines numerischen Modells. Aus einem Integrierer der $G'^*w$ für ein gegebenes $w$ berechnen kann, kann nun aus $\nabla_v J$ mittels \eqref{eq:adjointEssential} einfach $\nabla_u J$ errechnet werden. 
% Wenn $J$ einfach gewählt wurde, lässt sich daraus $\nabla_v J$ ebenfalls einfach berechnen. 
Um $\nabla_u J$ zu erhalten, muss zuerst $v = G(u)$ berechnet werden, danach $\nabla_v J$ und schlussendlich wieder $\nabla_u J$ durch \eqref{eq:adjointEssential}.

\section{Gradient des Zielfunktionals}
Um vorherige Betrachtungen auf die Ableitung des Zielfunktionals \eqref{eq:costfunctional} anwenden zu können wird die Gâteaux Ableitung des Kostenfunktionals \eqref{eq:costfunctional} zu einem Anfangswert $v$ gebildet
\begin{equation}
\label{eq:gatcost}
\begin{aligned}
 \gatdiff J(v)  &= \lim_{\tau\to 0} \frac{1}{\tau}\int_0^T H(x+\tau\gatdiff x)-H(x) dt\\
	    &= \lim_{\tau\to 0} \frac{1}{\tau}\int_0^T \int_0^1 \frac{d}{ds}H(x+s\tau\gatdiff x) dt\\
	    &= \lim_{\tau\to 0} \frac{1}{\tau}\int_0^T \int_0^1 \nabla_x H(x+s\tau\gatdiff x)\cdot \gatdiff x dt\\
	    &= \int_0^T \nabla_x H(x)\cdot \gatdiff x dt\\
	    &= \int_0^T \langle \nabla_x H(x), \gatdiff x \rangle dt\\  
\end{aligned}
\end{equation}
wobei $\nabla_x H(t)$ der Gradient von $H(x,t)$ ausgewertet an der Stelle $(x(t),t)$ und $\gatdiff x$ die Gâteaux-Ableitung von $x$, also eine Störung, beschreibt. Diese ist die Lösung von
\begin{equation}
\label{eq:tlm}
\begin{aligned}
  \frac{d \gatdiff x}{dt} &= \lim_{\tau\to 0}\frac{F(x+\tau \gatdiff x)-F(x)}{\tau}\\
			 &= \frac{d F(x+\tau\gatdiff x)}{d\tau} \Bigg\rvert_{\tau=0}\\
			 &= F'(t)\gatdiff x
\end{aligned} 
\end{equation}

und wird als \textit{Tangent Linear Model} bezeichnet. $F'(t)$ ist der Operator, der durch differenzieren von $F(x,t)$ nach $x$ ausgewertet an $x(t)$ entsteht. Da die gewöhnliche Differentialgleichung \eqref{eq:tlm} homogen und linear ist, hängt ihre Lösung linear vom Anfangswert $v$ ab und es gilt
\begin{equation}
\label{eq:resolvent}
 \gatdiff x(t) = R(t,0)v
\end{equation}
TODO Referenz auf ODE theory einfügen

Wie allgemein bekannt, ist $R(t,0)$ ein wohldefinierter linearer Operator. Dieser wird als \textit{Resolvent} bezeichnet (siehe dazu REFERENZ NOCH EINF*GEN). Er besitzt die folgenden Eigenschaften
\begin{align}
  R(t,t) &= I \label{eq:resolventPropertiesA}\\
  \frac{\partial}{\partial t}R(t,t') &= F'(t)R(t,t') \text{ für alle } t,t>0\label{eq:resolventPropertiesB}
\end{align}
Nun kann das Differential des Kostenfunktionals \eqref{eq:gatcost} mittels des Resolventen \eqref{eq:resolvent} und deren adjungiertem Operator $R^*(t,0)$ umgeschrieben werden zu
\begin{equation*}
\begin{aligned}
 \gatdiff J &= \int_0^T \langle \nabla_x H(t), R(t,0)v\rangle dt \\
	    &= \int_0^T \langle R^*(t,0) \nabla_x H(t), v\rangle dt \\
	    &= \left\langle \int_0^T R^*(t,0) \nabla_x H(t) dt, v\right\rangle \\
\end{aligned}
\end{equation*}
und es ergibt sich wie in den Betrachtungen zu Gleichung \eqref{eq:adjointEssential} %TODO die Anfangswertbedinungen einheitlich bennen v -> \gatdiff u oder so
\begin{equation}
\label{eq:gradCostFunctional}
 \nabla_v J = \int_0^T R^*(t,0) \nabla_x H(t) dt
\end{equation}
Der adjungierte Operator $R^*(t,0)$ des Resolventen $R(t,0)$ wird durch die Lösung des adjungierten Tangent Linear Models von \eqref{eq:tlm} 
\begin{equation}
\label{eq:adjointtlm}
 -\frac{d \gatdiff'x}{dt} = F'^*(t)\gatdiff'x
\end{equation}
beschrieben, wobei $\gatdiff'x \in\Hil$ und $F'^*(t)$ die Adjungierte von $F'(t)$ ist. 
Sei $S(t,t')$ der Resolvent von \eqref{eq:adjointtlm} zwischen den Zeitpunkten $t$ und $t'$. Für zwei Lösungen $\gatdiff x$ und $\gatdiff' x$ des Tangent Linear Models \eqref{eq:tlm} und deren Adjungierte \eqref{eq:adjointtlm} ist das innere Produkt $\langle \gatdiff x,\gatdiff' x\rangle$ konstant, da das innere Produkt der Ableitungen nach $t$ verschwindet:
\begin{equation}
\begin{aligned}
 \frac{d}{dt}\langle \gatdiff x(t),\gatdiff' x(t)\rangle  &= \left\langle \frac{d \gatdiff x}{dt}(t) ,\gatdiff' x\right\rangle +\left\langle \gatdiff x,\frac{d\gatdiff ' x}{dt}(t)\right\rangle \\
 &= \langle F'(t)\gatdiff x(t),\gatdiff 'x(t)\rangle - \langle \gatdiff x(t),F'^*(t)\gatdiff' x(t)\rangle\\
 &= 0
\end{aligned}
\end{equation}
Daraus folgt unmittelbar, dass die Lösungen zweier Anfangswerte $y,y' \in \Hil$ die Gleichung
\begin{equation*}
\langle R(t',t)y,y'\rangle = \langle y,S(t,t')y'\rangle 
\end{equation*}
erfüllen, da die Lösung des Tangent Linear Models \eqref{eq:tlm} für die Anfangsbedingung $y$ am Zeitpunkt $t$ gerade den Wert $R(t',t)y$ zum Zeitpunkt $t'$ und die Lösung des adjungierten Tangent Linear Models \eqref{eq:adjointtlm} für die Anfangsbedingung $y'$ am Zeitpunkt $t'$ den Wert $S(t,t')y'$ zum Zeitpunkt $t$ annimmt. Da dies für alle $y,y'$ gilt, ist $S(t,t')$ der adjungierte Operator von $R(t',t)$.
Für den Gradienten des Kostenfunktionals \eqref{eq:gradCostFunctional} entsteht somit
\begin{equation}
\label{eq:gradCostFunctionalAdjoint}
 \nabla_v J = \int_0^T S(0,t) \nabla_x H(t) dt
\end{equation}
Um den Gradienten des Kostenfunktionals nun darstellen zu können benötigen wir die \textit{Inhomogene Adjungierte Gleichung}
\begin{equation}
\label{eq:inhAdjEquation}
-d\gatdiff'x(t) = F'^*(t)\gatdiff'x - \nabla_x H(t)
\end{equation}
welche durch die Lösung 
\begin{equation}
\label{eq:solutionInhAdjEquation}
 \gatdiff'x(t) = \int_t^{t_1} S(t,\tau)\nabla_x H(\tau)d\tau
\end{equation}
mit $\gatdiff x(t_1)=0$ beschrieben ist. Dass \eqref{eq:solutionInhAdjEquation} die Inhomomgene Adjungierte Gleichung \eqref{eq:inhAdjEquation} löst lässt sich mittels den Eigenschaften des Resolventen \eqref{eq:resolventPropertiesA} und \eqref{eq:resolventPropertiesB} zeigen. Durch Substituieren erhält man
\begin{equation*}
 \begin{aligned}
  \frac{d\gatdiff'x}{dt} &= \frac{d}{dt} \int_t^{t_1} S(t,\tau)\nabla_x H(\tau)d\tau \\
			 &= \frac{d}{dt} \int_t^{t_1} G(t,\tau)d\tau 
\end{aligned}
\end{equation*}
Durch ableiten nach $t$ und der verallgemeinerten Leibniz Integral Formel (\ref{eq:genLeibnizIntRule}) folgt
\begin{equation*}
 \begin{aligned}
 \frac{d}{dt} \int_t^{t_1} G(t,\tau)d\tau  
			 &\overset{\eqref{eq:genLeibnizIntRule}}= G(t,t_1)\cdot 0 - G(t,t) + \int_t^{t_1} \frac{d}{dt}G(t,\tau) d\tau \\
			 &= -S(t,t)\nabla_x H(t) + \int_t^{t_1} \frac{d}{dt}S(t,\tau)\nabla_x H(\tau) d\tau \\
			 &\overset{\eqref{eq:resolventPropertiesA},\eqref{eq:resolventPropertiesB}}= -\nabla_x H(t) + \int_t^{t_1} F'^*(t)S(t,\tau)\nabla_x H(\tau) d\tau \\
			  &= -\nabla_x H(t) +F'^*(t) \int_t^{t_1} S(t,\tau)\nabla_x H(\tau) d\tau \\
			 &= -\nabla_x H(t) +F'^*(t) \gatdiff 'x(t) \\
 \end{aligned}
\end{equation*}
Die umgekehrte Richtung wird fast analog bewiesen; es gilt
\begin{equation*}
 -\frac{d\gatdiff 'x}{dt} = F'^*(t) \gatdiff'x - \nabla_x H(t)
			 = \frac{d}{dt} \int_t^{t_1} S(t,\tau) \nabla_x H(\tau) d\tau
\end{equation*}
Integration über $[t,t_1]$ liefert
\[
 \gatdiff 'x(t) -  \gatdiff 'x(t_1)  = \int_t^{t_1} S(t,\tau) \nabla_x H(\tau) d\tau
\]
Mit $ \gatdiff 'x(t_1) = 0$ und mit \eqref{eq:gradCostFunctionalAdjoint} folgt, dass $\nabla_v J = \gatdiff'x(0)$. Das bedeutet, dass sich der Gradient des Zielfunktionals mithilfe einer Rückwärtsintegration des Adjungierten Modells berechnen lässt.
Genauer werden folgende Schritte benötigt, um den Gradienten des Zielfunktionals \eqref{eq:costfunctional} zu berechnen

\begin{enumerate}
 \item Setze $v$ als Anfangswert des Modells \eqref{eq:odemodel} und löse dieses über das Intervall $[0,T]$, speichere berechnete Werte $x(t_i)$ ab\\
 ($0= t_0<~ t_1<\ldots<t_l=T$, $l\in \N$)
 \item Setze $\gatdiff 'x(T) = 0$, integriere die Inhomogene Adjungierte Gleichung \eqref{eq:inhAdjEquation} rückwärts in der Zeit von $T$ bis $0$, berechne zu den Zeitpunkten $t_i$ den Gradienten $F'^*(t_i)$ und $\nabla_x H(t_i)$ aus den gespeicherten Werten $x(t)$ aus Schritt 1.
 \item $\nabla_v J = \gatdiff 'x(t_0)$
\end{enumerate}

Übersetzt in Pseudocode lautet der Algorithmus

% \begin{algorithm}[H]
%  \algrenewcommand{\algorithmiccomment}[1]{\hfill{\scriptsize #1}}
%  \caption{\texttt{PlanC::calc\_kink\_partials}}
%  \label{alg:kinkPartials}
%  \begin{algorithmic}[1]
% 
%  \end{algorithmic}
%  \end{algorithm}


TODO: ALGORITHMUS HIER?

\section{Abstiegsmethoden}
Nun, da ein numerischer Weg gefunden wurde, $\nabla_v J$ effizient zu berechnen, stellt die Optimierung des Zielfunktional die letzte Hürde dar, der wir uns annehmen müssen. Das Ausgangsproblem besteht darin, über einer reellwertigen, differenzierbaren Funktion J
\begin{equation}
\label{eq:minProblem}
 \min_{x_0} J(x_0) 
\end{equation}
zu minimieren. Dies ist ein unrestringiertes Optimierungsproblem. 
 Im folgenden sei vorausgesetzt, dass für ein $\tilde x\in D$ die \textit{Niveaumenge}
 \[
  N(J,J(\tilde x)) = \left\{ x\in D \vert J(x)\leq J(\tilde x)\right\}
 \]

 von $J$ in $x\in \R^n$ kompakt sei. Unter dieser Voraussetzung existiert nach dem Satz von Weierstraß ein $\bar x \in N(J,J(\tilde x))$ mit 
 \[
  J(\bar x) \leq J(x) \forall x\in N(J,J(\tilde x))
 \]
 und damit ist für $x\in D\textbackslash N(J,J(\tilde x))$: $J(x)>J(\tilde x)> J(\bar x)$. (vgl. \cite[Satz 1.2.2]{alt2002nichtlineare})
 

Zur Charakerisierung von Lösungen von \eqref{eq:minProblem} ist folgender Satz über notwendige Bedingungen (vgl. \cite[vgl. Satz 3.1.1 ff.]{alt2002nichtlineare}) hilfreich:
\begin{theorem}[Notwendige Bedingung erster Ordnung] 
 Die Zielfunktion $J$ sei in $x\in D$, $D\subset \R^n$ differenzierbar. Ist $\bar x$ lokales Minimum von \eqref{eq:minProblem}, dann gilt
 \[
  \nabla J(\bar x)^\tr d \geq 0 \quad \forall d\in \R^n
 \]
 Wenn $d\in \R^n$ ist $(-d)\in \R^n$ und damit $\nabla J(\bar x)^\tr (-d) =  - \nabla J(\bar x)^\tr d  \geq 0$. Es folgt also
 \[
  \nabla J(\bar x)  =0 \in \R^n
 \]
\end{theorem}
 Der Beweis findet man ebenfalls in \cite[vgl. Satz 3.1.1 ff]{alt2002nichtlineare}.$\proofend$

Dieses Resultat wird zur Konstruktion von Abstiegsverfahren verwendet. Es gilt nämlich (\cite[vgl. Satz 4.1.1]{alt2002nichtlineare}) 
\begin{lemma}
 Die Funktion $J:\R^n\to \R^n$ sei differenzierbar in $x$. Weiter sei $d\in \R^n$ mit 
 \[
  \nabla J(x)^\tr d<0
 \]
 Dann gibt es ein $\bar \sigma>0$ mit $J(x+\bar \sigma d)< J(x)$ für alle $\sigma \in (0,\bar \sigma)$
\end{lemma}
Den Beweis findet man u.a. in \cite[vgl. Satz 4.1.1]{alt2002nichtlineare}. Ein Vektor $d$ heißt Abstiegsrichtung von $J$ im Punkt $x$, wenn $\nabla J(x)^\tr d<0$. Im Verfahren des steilsten Abstiegs wird gerade $d=- \nabla J(x)$ als Abstiegsrichtung verwendet, da 
\[
\nabla J(x)d = \nabla J(x) (-\nabla J(x)) = - \|\nabla J(x)\|^2 <0                                                                                                                                                                                                                                                                        \]
Für dieses Verfahren werden folgende Schritte ausgeführt
\begin{enumerate}
 \item Wähle Anfangspunkt $x^{(0)}$ und setze $k:=0$
 \item Überprüfe $\nabla J(x^{(k)}) == 0$?: Stopp
 \item Setze als Suchrichtung $d = - \nabla J(x^{(k)})$, berechne effiziente Schrittweite $\alpha_k$ und setze $x^{(k+1)} = x^{(k)}+ \alpha_k d^{(k)}$
 \item Setze $k:= k+1$ und gehe zu 2.
\end{enumerate}
